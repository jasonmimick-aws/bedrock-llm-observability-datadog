{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup\n",
    "\n",
    "The setup below shows in-code configuration. For most applications, we can also enable LLMObs simply by calling `ddtrace-run` with the appropriate env vars, [as seen here in our quickstart instructions](https://docs.datadoghq.com/tracing/llm_observability/quickstart/).\n",
    "\n",
    "The code below requires you to have already created an `.env` file with several configuration variables as explained in the README.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from ddtrace.llmobs import LLMObs\n",
    "\n",
    "LLMObs.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note for enterprise customers using secrets:**\n",
    "\n",
    "If you are using secrets, you can enable LLM Observability with more specific parameters as demonstrated below.\n",
    "\n",
    "```python\n",
    "LLMObs.enable(\n",
    "  ml_app=\"<YOUR_ML_APP_NAME>\",\n",
    "  api_key=\"<YOUR_DATADOG_API_KEY>\",\n",
    "  site=\"<YOUR_DATADOG_SITE>\",\n",
    "  agentless_enabled=True,\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing an LLM Call\n",
    "\n",
    "An LLM Span represents a call to a model. In this simple example, we are asking Claude via Amazon Bedrock to summarize a provided text and identify a list of topics from the text.\n",
    "\n",
    "Because we use Amazon Bedrock with Datadog's instrumentation, the call to the LLM is automatically traced:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-east-1'  # specify your region\n",
    ")\n",
    "\n",
    "def get_model_id(model_name=\"claude\"):\n",
    "    \"\"\"\n",
    "    Get the model ID based on the model name\n",
    "    Default is Claude-2\n",
    "    \"\"\"\n",
    "    model_mapping = {\n",
    "        \"claude\": \"anthropic.claude-v2\",  # Using Claude-2 as default\n",
    "        \"claude-2\": \"anthropic.claude-v2\",\n",
    "        \"claude-instant\": \"anthropic.claude-instant-v1\"\n",
    "    }\n",
    "    return model_mapping.get(model_name, model_mapping[\"claude\"])\n",
    "\n",
    "\n",
    "sys_prompt = \"\"\"\n",
    "Your task is to \n",
    "1. Summarize the given text at a 6th grade reading level in no more than 2 sentences.\n",
    "2. Identify what topics the text belongs to that would allow you to categorize it in a school library.\n",
    "Format your output strictly following this JSON convention:\n",
    "{\t\n",
    "    \"topics\": <[insert array of topics here]>\n",
    "    \"summary\": <insert summary here>\n",
    "}\n",
    "\t\"\"\"\n",
    "\n",
    "\n",
    "def summarize(text, model_name=\"claude\", prompt=sys_prompt):\n",
    "    # Construct the message in Claude's format\n",
    "    message = f\"{prompt}\\n\\nHuman: {text}\\n\\nAssistant: \"\n",
    "    \n",
    "    try:\n",
    "        response = bedrock.invoke_model(\n",
    "            modelId=get_model_id(model_name),\n",
    "            body=json.dumps({\n",
    "                \"prompt\": message,\n",
    "                \"max_tokens_to_sample\": 1000,  # Changed from max_tokens\n",
    "                \"temperature\": 0,\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "            })\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        print(f\"Response body: {response_body}\")\n",
    "\n",
    "        #return json.loads(response_body.get('completion'))\n",
    "        \n",
    "\n",
    "        completion_text = response_body.get('completion', '').strip()\n",
    "        \n",
    "        # Find the JSON part within the completion\n",
    "        try:\n",
    "            # Look for content between curly braces\n",
    "            json_start = completion_text.find('{')\n",
    "            json_end = completion_text.rfind('}') + 1\n",
    "            if json_start >= 0 and json_end > 0:\n",
    "                json_str = completion_text[json_start:json_end]\n",
    "                return json.loads(json_str)\n",
    "            else:\n",
    "                raise ValueError(\"No JSON found in response\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON from response\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Bedrock: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "ONE JANUARY day, thirty years ago, the little town of Hanover, anchored on a windy Nebraska tableland, was trying not to be blown away. A mist of fine snowflakes was curling and eddying about the cluster of low drab buildings huddled on the gray prairie, under a gray sky. The dwelling-houses were set about haphazard on the tough prairie sod; some of them looked as if they had been moved in overnight, and others as if they were straying off by themselves, headed straight for the open plain. None of them had any appearance of permanence, and the howling wind blew under them as well as over them. The main street was a deeply rutted road, now frozen hard, which ran from the squat red railway station and the grain \"elevator\" at the north end of the town to the lumber yard and the horse pond at the south end. On either side of this road straggled two uneven rows of wooden buildings; the general merchandise stores, the two banks, the drug store, the feed store, the saloon, the post-office. The board sidewalks were gray with trampled snow, but at two o'clock in the afternoon the shopkeepers, having come back from dinner, were keeping well behind their frosty windows.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response body: {'type': 'completion', 'completion': ' Here is a 6th grade level summary of the text in 2 sentences:\\n\\n{\\n    \"topics\": [\"Geography\", \"History\", \"Small Towns\"],\\n    \"summary\": \"Thirty years ago, the small prairie town of Hanover was trying not to be blown away by wind and snow, with its basic shops and houses spread out on the flat, treeless land.\"  \\n}', 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'topics': ['Geography', 'History', 'Small Towns'],\n",
       " 'summary': 'Thirty years ago, the small prairie town of Hanover was trying not to be blown away by wind and snow, with its basic shops and houses spread out on the flat, treeless land.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "failed to send, dropping 1 traces to intake at https://llmobs-intake.datadoghq.com/api/v2/llmobs after 5 retries, 1 additional messages skipped\n"
     ]
    }
   ],
   "source": [
    "summarize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the trace in Datadog\n",
    "\n",
    "Now, check out the [LLM Observability interface](https://app.datadoghq.com/llm) in Datadog. You should see a trace that describes the LLM call, including the system prompt, the user prompt, and the response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional resources\n",
    "\n",
    "- [List of all integrations supported by Datadog's LLM Observability product](https://docs.datadoghq.com/tracing/llm_observability/sdk/#llm-integrations)\n",
    "- [Instructions for manually instrumenting an LLM Span](https://docs.datadoghq.com/llm_observability/setup/sdk/python/#llm-span)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
