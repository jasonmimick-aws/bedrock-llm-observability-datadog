{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from ddtrace.llmobs import LLMObs\n",
    "\n",
    "LLMObs.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and tracing a simple LLM service\n",
    "\n",
    "In this notebook, we are building a service that takes a free text query about art from a user, and feeds it into the Metropolitan Museum of Art API to get a list of artwork.\n",
    "\n",
    "The steps are:\n",
    "\n",
    "1. Take a query from a user.\n",
    "2. Parse that query via a call to Amazon Bedrock.\n",
    "3. Send the parsed query to the [Metropolitan Museum of Art API](https://metmuseum.github.io/#search).\n",
    "4. Return a list of URLs to the user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating the tool to fetch data from the Met API\n",
    "\n",
    "In the next cell, we create and instrument a \"tool\": a function that can send a query to the Met API's `/search` endpoint. The actual query will be created by an LLM call in a following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from ddtrace.llmobs.decorators import *\n",
    "\n",
    "SEARCH_ENDPOINT = \"https://collectionapi.metmuseum.org/public/collection/v1/search\"\n",
    "MAX_RESULTS = 5\n",
    "\n",
    "\n",
    "# learn more about tool calls in our docs:\n",
    "# https://docs.datadoghq.com/tracing/llm_observability/sdk/#tool-span\n",
    "\n",
    "\n",
    "@tool()\n",
    "def fetch_met_urls(query_parameters):\n",
    "    # We annotate the tool call with input_data here\n",
    "    LLMObs.annotate(\n",
    "        input_data=query_parameters,\n",
    "    )\n",
    "    response = requests.get(SEARCH_ENDPOINT, params=query_parameters)\n",
    "    response.raise_for_status()\n",
    "    object_ids = response.json().get(\"objectIDs\")\n",
    "    objects_to_return = object_ids[:MAX_RESULTS] if object_ids else []\n",
    "    urls = [\n",
    "        f\"https://www.metmuseum.org/art/collection/search/{objectId}\"\n",
    "        for objectId in objects_to_return\n",
    "    ]\n",
    "    # We annotate the tool call with output_data here\n",
    "    LLMObs.annotate(\n",
    "        output_data=urls,\n",
    "    )\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://metmuseum.github.io/#search\n",
    "fetch_met_urls_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"fetch_met_urls\",\n",
    "        \"description\": \"Submits a query to the MET API and returns urls of relevant artworks\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query_parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"q\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Represents the users query. Required. Add as many search terms from the query as you can. 'medieval portraits', 'french impressionist paintings', etc.\",\n",
    "                        },\n",
    "                        \"title\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Limits the query to only apply to the title field.\",\n",
    "                        },\n",
    "                        \"tags\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Limits the query to only apply to the tags field.\",\n",
    "                        },\n",
    "                        \"isOnView\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Returns objects that match the query and are on view in the museum.\",\n",
    "                        },\n",
    "                        \"artistOrCulture\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Returns objects that match the query, specifically searching against the artist name or culture field for objects.\",\n",
    "                        },\n",
    "                        \"medium\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": 'Returns objects that match the query and are of the specified medium or object type. Examples include: \"Ceramics\", \"Furniture\", \"Paintings\", \"Sculpture\", \"Textiles\", etc.',\n",
    "                        },\n",
    "                        \"geoLocation\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": 'Returns objects that match the query and the specified geographic location. Examples include: \"Europe\", \"France\", \"Paris\", \"China\", \"New York\", etc.',\n",
    "                        },\n",
    "                        \"dateBegin\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"You must use both dateBegin and dateEnd, or neither. Returns objects that match the query and fall between the dateBegin and dateEnd parameters. Examples include: dateBegin=1700&dateEnd=1800 for objects from 1700 A.D. to 1800 A.D., dateBegin=-100&dateEnd=100 for objects between 100 B.C. to 100 A.D.\",\n",
    "                        },\n",
    "                        \"dateEnd\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"You must use both dateBegin and dateEnd, or neither. Returns objects that match the query and fall between the dateBegin and dateEnd parameters. Examples include: dateBegin=1700&dateEnd=1800 for objects from 1700 A.D. to 1800 A.D., dateBegin=-100&dateEnd=100 for objects between 100 B.C. to 100 A.D.\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"q\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating an LLM call to handle parsing user input into a standardized query\n",
    "\n",
    "We are using Amazon Bedrock with Claude, which is automatically instrumented by Datadog:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=os.environ.get(\"AWS_REGION\", \"us-east-1\")\n",
    ")\n",
    "\n",
    "def get_model_id(model_name=\"claude\"):\n",
    "    \"\"\"\n",
    "    Get the model ID based on the model name\n",
    "    Default is Claude-2\n",
    "    \"\"\"\n",
    "    model_mapping = {\n",
    "        \"claude\": \"anthropic.claude-v2\",  # Using Claude-2 as default\n",
    "        \"claude-2\": \"anthropic.claude-v2\",\n",
    "        \"claude-instant\": \"anthropic.claude-instant-v1\"\n",
    "    }\n",
    "    return model_mapping.get(model_name, model_mapping[\"claude\"])\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Example query inputs and outputs for the fetch_met_urls function:\n",
    "\n",
    "query: medieval french tapestry painting\n",
    "output: {'q': 'medieval french tapestry painting', geoLocation: 'France', medium: 'Textiles', dateBegin: 1000, dateEnd: 1500}\n",
    "\n",
    "query: etruscan urns\n",
    "output: {'q': 'etruscan urn', geoLocation: 'Italy', medium: 'Travertine'}\n",
    "\n",
    "query: Cambodian hats from the 18th and 19th centuries\n",
    "output: {'q': 'Cambodian hats', geolocation: 'Cambodia', 'dateBegin': 1700, 'dateEnd': 1900}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def parse_query(message):\n",
    "    # Construct the message in Claude's format with tool definition\n",
    "    tool_definition = {\n",
    "        \"name\": \"fetch_met_urls\",\n",
    "        \"description\": \"Fetch URLs from the Metropolitan Museum of Art API\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query_parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"description\": \"Parameters for the Met API query\",\n",
    "                    \"properties\": {\n",
    "                        \"q\": {\"type\": \"string\", \"description\": \"Search term\"},\n",
    "                        \"geoLocation\": {\"type\": \"string\", \"description\": \"Geographic location\"},\n",
    "                        \"medium\": {\"type\": \"string\", \"description\": \"Medium of the artwork\"},\n",
    "                        \"dateBegin\": {\"type\": \"integer\", \"description\": \"Start year\"},\n",
    "                        \"dateEnd\": {\"type\": \"integer\", \"description\": \"End year\"}\n",
    "                    },\n",
    "                    \"required\": [\"q\"]\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query_parameters\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    prompt = f\"{system_prompt}\\n\\nHuman: {message}\\n\\nAssistant: I'll help parse this query for the Metropolitan Museum API.\\n\\n<function_call>\\nfetch_met_urls\\n\"\n",
    "    \n",
    "    try:\n",
    "        response = bedrock.invoke_model(\n",
    "            modelId=get_model_id(),\n",
    "            body=json.dumps({\n",
    "                \"prompt\": prompt,\n",
    "                \"max_tokens_to_sample\": 1000,\n",
    "                \"temperature\": 0,\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                \"tools\": [tool_definition]\n",
    "            })\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        completion = response_body.get('completion', '')\n",
    "        \n",
    "        # Extract the JSON from the function call response\n",
    "        if '<function_call>' in completion and '</function_call>' in completion:\n",
    "            # Extract content between function call tags\n",
    "            start_idx = completion.find('<function_call>')\n",
    "            end_idx = completion.find('</function_call>')\n",
    "            function_content = completion[start_idx:end_idx + len('</function_call>')]\n",
    "            \n",
    "            # Extract the JSON part\n",
    "            json_start = function_content.find('{')\n",
    "            json_end = function_content.rfind('}') + 1\n",
    "            if json_start >= 0 and json_end > 0:\n",
    "                json_str = function_content[json_start:json_end]\n",
    "                parsed_json = json.loads(json_str)\n",
    "                return parsed_json.get(\"query_parameters\", {})\n",
    "        \n",
    "        # Fallback parsing if the above doesn't work\n",
    "        # Look for any JSON-like structure in the completion\n",
    "        json_start = completion.find('{')\n",
    "        json_end = completion.rfind('}') + 1\n",
    "        if json_start >= 0 and json_end > 0:\n",
    "            json_str = completion[json_start:json_end]\n",
    "            try:\n",
    "                parsed_json = json.loads(json_str)\n",
    "                if \"query_parameters\" in parsed_json:\n",
    "                    return parsed_json[\"query_parameters\"]\n",
    "                return parsed_json\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Failed to parse JSON from response\")\n",
    "        \n",
    "        print(f\"Could not extract query parameters from response: {completion}\")\n",
    "        return {\"q\": message}  # Fallback to using the raw message as the query\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Bedrock: {str(e)}\")\n",
    "        return {\"q\": message}  # Fallback to using the raw message as the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating the `find_artworks` function\n",
    "\n",
    "Finally, we create a `find_artworks` function here ties the LLM call and tool call together. We annotate this as a workflow span:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn more about workflow spans in our docs:\n",
    "# https://docs.datadoghq.com/llm_observability/setup/sdk/python/#workflow-span\n",
    "@workflow()\n",
    "def find_artworks(question):\n",
    "    # We annotate the workflow span with input_data here\n",
    "    LLMObs.annotate(\n",
    "        input_data=question,\n",
    "    )\n",
    "    query = parse_query(question)\n",
    "    print(\"Parsed query parameters\", query)\n",
    "    urls = fetch_met_urls(query)\n",
    "    # We annotate the workflow span with output_data here\n",
    "    LLMObs.annotate(\n",
    "        output_data=urls,\n",
    "    )\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed query parameters {'q': 'french revolution', 'medium': 'Paintings'}\n"
     ]
    }
   ],
   "source": [
    "urls = find_artworks(\"paintings of the french revolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.metmuseum.org/art/collection/search/488319',\n",
      " 'https://www.metmuseum.org/art/collection/search/437925',\n",
      " 'https://www.metmuseum.org/art/collection/search/436106',\n",
      " 'https://www.metmuseum.org/art/collection/search/789578',\n",
      " 'https://www.metmuseum.org/art/collection/search/436840']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pp(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the trace in Datadog\n",
    "\n",
    "Now, try checking out the [LLM Observability interface](https://app.datadoghq.com/llm) in Datadog. You should see a trace that describes the workflow we just ran.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
